{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "target_name_dict = {'astro-ph.GA' : 0,\n",
    "                    'astro-ph.SR' : 1,\n",
    "                    'astro-ph.IM' : 2,\n",
    "                    'astro-ph.EP' : 3,\n",
    "                    'astro-ph.HE' : 4,\n",
    "                    'astro-ph.CO' : 5\n",
    "                }\n",
    "label2target = { v:k for k,v in target_name_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.HDFStore(\"../data/2014astroph_p.h5\", \"r\")\n",
    "df['/df'].keys()\n",
    "abstracts = df['/df']['abstract']\n",
    "labels = np.array(df['/df']['label'])\n",
    "df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6211 astro-ph.HE\n",
      "Very recently, the IceCube Collaboration reported a flux of neutrinos in the\n",
      "energy range 50 TeV < E_\\nu < 2 PeV, which departs from expectations from\n",
      "atmospheric background at the 5.7\\sigma level. This flux is in remarkable\n",
      "agreement with the expected diffuse flux of neutrinos from starburst galaxies,\n",
      "and the 3 highest energy events have uncertainty contours encompassing some of\n",
      "such systems. These events, all of which have well-measured energies above 1\n",
      "PeV, exhibit shower topologies, for which the angular resolution is about\n",
      "15^\\circ. Due to this angular uncertainty and the a posteriori nature of cuts\n",
      "used in our study it is not possible to assign a robust statistical\n",
      "significance to this association. Using muon tracks, which have angular\n",
      "resolution < 1^\\circ, we compute the number of observations required to make a\n",
      "statistically significant statement, and show that in a few years of operation\n",
      "the upgraded IceCube detector should be able to confirm or refute this\n",
      "hypothesis. We also note that double bang topology rates constitute a possible\n",
      "discriminator among various astrophysical sources.\n"
     ]
    }
   ],
   "source": [
    "j = np.random.randint(len(labels))\n",
    "print(j, label2target[labels[j]])\n",
    "print(abstracts[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "maxlen = 150\n",
    "max_words = 10000 # Top 10000 words\n",
    "training_samples = 6000 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30677 unique tokens\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(abstracts)\n",
    "sequences = tokenizer.texts_to_sequences(abstracts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Found %s unique tokens\" % len(word_index))\n",
    "\n",
    "word_index_reverse = dict()\n",
    "\n",
    "for k, v in word_index.items():\n",
    "    word_index_reverse[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences=sequences, maxlen=maxlen)\n",
    "indices = np.arange(abstracts.shape[0])\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "data = data[indices]\n",
    "\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "\n",
    "x_test = data[training_samples:]\n",
    "y_test = labels[training_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/41971587/how-to-convert-predicted-sequence-back-to-text-in-keras\n",
    "# Creating a reverse dictionary\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "# Function takes a tokenized sentence and returns the words\n",
    "def sequence_to_text(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "\n",
    "# Creating texts \n",
    "my_texts = list(map(sequence_to_text, data))\n",
    "\n",
    "# alternative way\n",
    "my_texts_2 = tokenizer.sequences_to_texts(sequences=sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2788 astro-ph.CO\n",
      "['ia', 'data', 'in', 'recent', 'years', 'we', 'use', 'the', 'union2', '1', 'data', 'to', 'give', 'a', 'simple', 'classification', 'of', 'such', 'studies', 'for', 'the', 'first', 'time', 'because', 'the', 'maximum', 'anisotropic', 'direction', 'is', 'independent', 'of', 'isotropic', 'dark', 'energy', 'models', 'we', 'adopt', 'two', 'cosmological', 'models', 'lambda', 'cdm', 'w', 'cdm', 'for', 'the', 'hemisphere', 'comparison', 'analysis', 'and', 'lambda', 'cdm', 'model', 'for', 'dipole', 'fit', 'approach', 'in', 'hemisphere', 'comparison', 'method', 'the', 'matter', 'density', 'and', 'the', 'equation', 'of', 'state', 'of', 'dark', 'energy', 'are', 'adopted', 'as', 'the', 'diagnostic', 'in', 'the', 'lambda', 'cdm', 'model', 'and', 'w', 'cdm', 'model', 'respectively', 'in', 'dipole', 'fit', 'approach', 'we', 'fit', 'the', 'fluctuation', 'of', 'distance', 'modulus', 'we', 'find', 'that', 'there', 'is', 'a', 'null', 'signal', 'for', 'the', 'hemisphere', 'comparison', 'method', 'while', 'a', 'preferred', 'direction', 'b', '14', '3', 'circ', 'pm', '10', '1', 'circ', 'l', '1', 'circ', 'pm', '16', '2', 'circ', 'for', 'the', 'dipole', 'fit', 'method', 'this', 'result', 'indicates', 'that', 'the', 'dipole', 'fit', 'is', 'more', 'sensitive', 'than', 'the', 'hemisphere', 'comparison', 'method']\n"
     ]
    }
   ],
   "source": [
    "j = np.random.randint(len(x_train))\n",
    "print(j, label2target[y_train[j]])\n",
    "print(my_texts[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 1,017,222\n",
      "Trainable params: 1,017,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embeddings_dim = 100\n",
    "model.add(layers.Embedding(max_words, embeddings_dim, input_length=maxlen))\n",
    "#model.add(layers.Flatten())\n",
    "#model.add(layers.Dense(64, activation='relu', input_shape=(maxlen,)))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[0].set_weights([embedding_matrix])\n",
    "#model.layers[0].trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4200 samples, validate on 1800 samples\n",
      "Epoch 1/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 1.5056 - acc: 0.4114 - val_loss: 1.3825 - val_acc: 0.4761\n",
      "Epoch 2/20\n",
      "4200/4200 [==============================] - 15s 4ms/step - loss: 1.2574 - acc: 0.5110 - val_loss: 1.2900 - val_acc: 0.5050\n",
      "Epoch 3/20\n",
      "4200/4200 [==============================] - 15s 4ms/step - loss: 1.0792 - acc: 0.5760 - val_loss: 1.2797 - val_acc: 0.5106\n",
      "Epoch 4/20\n",
      "4200/4200 [==============================] - 15s 4ms/step - loss: 0.9039 - acc: 0.6367 - val_loss: 1.2789 - val_acc: 0.5472\n",
      "Epoch 5/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.7552 - acc: 0.7055 - val_loss: 1.7578 - val_acc: 0.5250\n",
      "Epoch 6/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.6226 - acc: 0.7969 - val_loss: 1.1802 - val_acc: 0.5800\n",
      "Epoch 7/20\n",
      "4200/4200 [==============================] - 15s 4ms/step - loss: 0.4777 - acc: 0.8631 - val_loss: 1.3916 - val_acc: 0.6000\n",
      "Epoch 8/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.3819 - acc: 0.8974 - val_loss: 1.2028 - val_acc: 0.5928\n",
      "Epoch 9/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.2890 - acc: 0.9248 - val_loss: 1.2781 - val_acc: 0.6067\n",
      "Epoch 10/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.2091 - acc: 0.9445 - val_loss: 1.4412 - val_acc: 0.6233\n",
      "Epoch 11/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.1420 - acc: 0.9633 - val_loss: 1.4132 - val_acc: 0.6067\n",
      "Epoch 12/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.1072 - acc: 0.9717 - val_loss: 1.5269 - val_acc: 0.6150\n",
      "Epoch 13/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.0828 - acc: 0.9807 - val_loss: 1.5045 - val_acc: 0.6350\n",
      "Epoch 14/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.0646 - acc: 0.9840 - val_loss: 1.5875 - val_acc: 0.6233\n",
      "Epoch 15/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.0562 - acc: 0.9857 - val_loss: 1.6385 - val_acc: 0.6306\n",
      "Epoch 16/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.0366 - acc: 0.9912 - val_loss: 1.7019 - val_acc: 0.6411\n",
      "Epoch 17/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.0325 - acc: 0.9914 - val_loss: 1.9060 - val_acc: 0.6061\n",
      "Epoch 18/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.0311 - acc: 0.9914 - val_loss: 1.8298 - val_acc: 0.6394\n",
      "Epoch 19/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.0268 - acc: 0.9933 - val_loss: 1.9104 - val_acc: 0.6367\n",
      "Epoch 20/20\n",
      "4200/4200 [==============================] - 16s 4ms/step - loss: 0.0124 - acc: 0.9974 - val_loss: 2.1351 - val_acc: 0.6350\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                   epochs=20,\n",
    "                   batch_size=32,\n",
    "                   validation_split=0.3)\n",
    "#model.save_weights('pre_trained_glove_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2794/2794 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test_one_hot)\n",
    "class_prediction = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0265545240878717, 0.6528274874304906]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1 1692  245  131  146 7472   10   16  785  789    6    4   24  571\n",
      " 6236    2   65  727   13   18  423   18   79   10   33    2   20   79\n",
      "   48  296 2001    6  926   10  188  441  160   22   79   48  296    1\n",
      " 3261  131  597 3910    9  223 1264   11  673  810   12  147   10 1811\n",
      "  584 5151   33  673  810 1716   14    2    1   44    2 5151   33 1460\n",
      " 1245   97   12 1545    6 1926  492    2    1  147  178    2   83 1174\n",
      "  553   33 1164   76   24    3  823  264 1102  457  160   85    8   21\n",
      "  301  155    2 1342 1204    3   92   19    4 1767  155    2  673 1204\n",
      "   18   83    9 1660  999   10  264   35    8  418   11  673  810    5\n",
      "    1  971  158   27   19  933    6   50  481   46    1 1342  810 3281\n",
      "  727   11   12  672    6  160   25   10  110   33]\n",
      "['the', 'eclipsing', 'binary', 'sample', 'if', 'unaccounted', 'for', 'this', 'bias', 'leads', 'to', 'a', 'mass', 'dependent', 'underestimate', 'of', 'stellar', 'radii', 'by', 'as', 'much', 'as', '4', 'for', 'stars', 'of', '0', '4', 'm', 'sun', 'decreasing', 'to', 'zero', 'for', 'masses', 'above', 'about', '1', '4', 'm', 'sun', 'the', 'asteroseismic', 'sample', 'suggests', 'albeit', 'with', 'significant', 'uncertainty', 'that', 'systematic', 'errors', 'are', 'small', 'for', 'slowly', 'rotating', 'inactive', 'stars', 'systematic', 'errors', 'arising', 'from', 'of', 'the', 'models', 'of', 'inactive', 'stars', 'probably', 'exist', 'but', 'are', 'difficult', 'to', 'assess', 'because', 'of', 'the', 'small', 'number', 'of', 'well', 'characterized', 'comparison', 'stars', 'having', 'low', 'mass', 'and', 'slow', 'rotation', 'poor', 'information', 'about', 'z', 'is', 'an', 'important', 'source', 'of', 'random', 'error', 'and', 'may', 'be', 'a', 'minor', 'source', 'of', 'systematic', 'error', 'as', 'well', 'with', 'suitable', 'corrections', 'for', 'rotation', 'it', 'is', 'likely', 'that', 'systematic', 'errors', 'in', 'the', 'rho', 'method', 'can', 'be', 'comparable', 'to', 'or', 'smaller', 'than', 'the', 'random', 'errors', 'yielding', 'radii', 'that', 'are', 'accurate', 'to', 'about', '2', 'for', 'most', 'stars']\n",
      "astro-ph.SR\n",
      "prediction:  astro-ph.SR\n"
     ]
    }
   ],
   "source": [
    "jj = np.random.randint(len(x_test))\n",
    "print(x_test[jj])\n",
    "print(my_texts[training_samples+jj])\n",
    "print(label2target[y_test[jj]])\n",
    "print(\"prediction: \", label2target[class_prediction[jj]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    7\n",
      "  5063    4  310    2  285  409   11  568    1 1272    2  147 3026    5\n",
      "     4 1735  118 1890    2    4 1995  505    3    4]]\n",
      "prediction:  [2.3874557e-02 5.5116252e-03 7.4725397e-02 8.9477998e-01 3.3034431e-04\n",
      " 7.7814108e-04]\n",
      "predicted category:  astro-ph.EP\n"
     ]
    }
   ],
   "source": [
    "abstract_testing = \"We formulate a set of linear equations that describe the behaviour of small eccentricities in a protoplanetary system consisting of a gaseous disc and a planet.\"\n",
    "seq_testing = tokenizer.texts_to_sequences([[ w for w in abstract_testing.split(' ')]])\n",
    "data_testing = pad_sequences(sequences=seq_testing, maxlen=maxlen)\n",
    "print(data_testing)\n",
    "classes_testing = model.predict(data_testing)\n",
    "print(\"prediction: \", classes_testing[0])\n",
    "print(\"predicted category: \", label2target[np.argmax(classes_testing[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f080d98e6d8>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(history.epoch, history.history['loss'], 'bo')\n",
    "ax.plot(history.epoch, history.history['val_loss'], 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2",
   "language": "python",
   "name": "tf-gpu-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
